{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q0jEeQOvZmK"
      },
      "source": [
        "# WhisperX for uploading files\n",
        "\n",
        "Upload your local files to the Colab Files from the left sidebar.\n",
        "\n",
        "从左侧将视频音频文件上传到Colab，然后运行即可下载生成好的字幕文件。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9Pgww7RuFUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89139db9-4c65-47f2-8766-0aed4a64bbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  3 05:49:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# @title *通用参数/Required settings:**\n",
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# @markdown #### **Initial prompt**\n",
        "# @markdown Prompts can be very helpful for correcting specific words or acronyms that the model often misrecognizes in the audio.\n",
        "prompt = \"ChatGPT, LLM, DALL-E,Turbo\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### **Directory Path**\n",
        "# @markdown where your audio-video files are located from Coloab\n",
        "directory_path = \"/content\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### Model\n",
        "model_size = \"large-v3\"  # @param [\"base\", \"base.en\", \"small\", \"small.en\",\"medium\", \"medium.en\", \"large-v1\",\"large-v2\",\"large-v3\"]\n",
        "\n",
        "# @markdown #### Language\n",
        "language = \"auto\" # @param [\"auto\", \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\", \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\", \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\", \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\", \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\", \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\", \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\", \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\", \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\", \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\"]\n",
        "\n",
        "\n",
        "# @markdown #### Assign speaker labels\n",
        "# @markdown Recognize speakers\n",
        "assign_speaker_lable = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown #### Align whisper output\n",
        "align_whisper_output = True # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80yOVjb-vAsD"
      },
      "source": [
        "conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.4 -c pytorch -c nvidia# Install WhisperX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hcc35ui3ux8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa5a4cd-35af-4362-9a30-2d766665b17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Collecting ctranslate2==4.5.0\n",
            "  Downloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.5.0) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.5.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.5.0) (6.0.2)\n",
            "Downloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ctranslate2\n",
            "Successfully installed ctranslate2-4.5.0\n",
            "Collecting git+https://github.com/m-bain/whisperx.git\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-ula_1ve7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-ula_1ve7\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 598, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 159, in unpack_url\n",
            "    unpack_vcs_link(link, location, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 81, in unpack_vcs_link\n",
            "    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 589, in unpack\n",
            "    self.obtain(location, url=url, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 502, in obtain\n",
            "    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/vcs/git.py\", line 277, in fetch_new\n",
            "    self.run_command(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 631, in run_command\n",
            "    return call_subprocess(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 1703, in print\n",
            "    extend(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/segment.py\", line 197, in <genexpr>\n",
            "    result_segments = (\n",
            "                      ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 1332, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 694, in __rich_console__\n",
            "    lines = self.wrap(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 1227, in wrap\n",
            "    for line in self.split(allow_blank=True):\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 1080, in split\n",
            "    return Lines([self.copy()])\n",
            "                  ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 444, in copy\n",
            "    copy_self = Text(\n",
            "                ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 155, in __init__\n",
            "    sanitized_text = strip_control_codes(text)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/control.py\", line 198, in strip_control_codes\n",
            "    return text.translate(_translate_table)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "! pip install ctranslate2==4.5.0\n",
        "! pip install git+https://github.com/m-bain/whisperx.git\n",
        "\n",
        "# ! pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "\n",
        "# !pip install git+https://github.com/federicotorrielli/BetterWhisperX\n",
        "\n",
        "# !pip install git+https://github.com/Hasan-Naseer/whisperX.git@release/latest-faster-whisper-version\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJXxWPzU7c6",
        "outputId": "2913330f-c538-454e-bd34-2a9031423035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# Please BE VERY CAREFUL, this will link your entire drive.\n",
        "# So don't edit code, except the one that says 'Customize the following options',\n",
        "# or you might mess up your files.\n",
        "# IF YOU DO NO WANT TO LINK DRIVE, please see below for an alternative!\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998j5EKSuFy7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEqkpyuQL5_"
      },
      "source": [
        "# Get Subtitle Files using WhisperX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qWk9Y3Uxv9qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b7f7a6-2428-4bb9-d755-8541d4152c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/media_proc/speedreg/in/DiaryofaWimpyKid16.mp3\n",
            "DiaryofaWimpyKid16.mp3\n",
            "/gdrive/MyDrive/media_proc/speedreg/out/DiaryofaWimpyKid16.mp3\n",
            "2025-03-03 05:46:10.676299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740980770.975008    1485 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740980771.048566    1485 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-03 05:46:11.622361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "tokenizer.json:   0% 0.00/2.48M [00:00<?, ?B/s]\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 2.13MB/s]\n",
            "\n",
            "vocabulary.json:   0% 0.00/1.07M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 100% 2.39k/2.39k [00:00<00:00, 12.3MB/s]\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 2.48M/2.48M [00:00<00:00, 27.6MB/s]\n",
            "vocabulary.json: 100% 1.07M/1.07M [00:00<00:00, 10.7MB/s]\n",
            "\n",
            "\n",
            "model.bin:   0% 10.5M/3.09G [00:00<00:35, 87.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   1% 31.5M/3.09G [00:00<00:21, 145MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.bin:   2% 62.9M/3.09G [00:00<00:16, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   3% 83.9M/3.09G [00:00<00:15, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   3% 105M/3.09G [00:00<00:15, 196MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.bin:   4% 126M/3.09G [00:00<00:15, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   5% 147M/3.09G [00:00<00:16, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   5% 168M/3.09G [00:00<00:16, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   6% 189M/3.09G [00:01<00:15, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   7% 210M/3.09G [00:01<00:15, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   7% 231M/3.09G [00:01<00:15, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   8% 252M/3.09G [00:01<00:14, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:   9% 283M/3.09G [00:01<00:13, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  10% 304M/3.09G [00:01<00:14, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  11% 325M/3.09G [00:01<00:15, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  11% 346M/3.09G [00:01<00:15, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  12% 367M/3.09G [00:02<00:14, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  13% 388M/3.09G [00:02<00:14, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  13% 409M/3.09G [00:02<00:14, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  14% 430M/3.09G [00:05<02:10, 20.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  15% 451M/3.09G [00:05<01:36, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  15% 472M/3.09G [00:05<01:11, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  16% 493M/3.09G [00:05<00:54, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  17% 514M/3.09G [00:05<00:42, 61.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  17% 535M/3.09G [00:06<00:33, 75.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  18% 556M/3.09G [00:06<00:27, 91.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  19% 577M/3.09G [00:06<00:23, 108MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.bin:  19% 598M/3.09G [00:06<00:20, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  20% 619M/3.09G [00:06<00:17, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  21% 640M/3.09G [00:06<00:16, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  21% 661M/3.09G [00:06<00:15, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  22% 682M/3.09G [00:06<00:14, 169MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  23% 703M/3.09G [00:06<00:13, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  23% 724M/3.09G [00:07<00:12, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  24% 744M/3.09G [00:07<00:12, 183MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  25% 765M/3.09G [00:07<00:12, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  25% 786M/3.09G [00:07<00:11, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  26% 818M/3.09G [00:07<00:11, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  28% 849M/3.09G [00:07<00:10, 206MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  29% 881M/3.09G [00:07<00:10, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  30% 912M/3.09G [00:08<00:11, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  30% 933M/3.09G [00:08<00:11, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  31% 954M/3.09G [00:08<00:11, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  32% 975M/3.09G [00:08<00:11, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  32% 996M/3.09G [00:08<00:11, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  33% 1.03G/3.09G [00:08<00:10, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  34% 1.05G/3.09G [00:08<00:10, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  35% 1.07G/3.09G [00:08<00:10, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  35% 1.09G/3.09G [00:08<00:10, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  36% 1.11G/3.09G [00:09<00:10, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  37% 1.14G/3.09G [00:09<00:09, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  38% 1.17G/3.09G [00:09<00:09, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  39% 1.20G/3.09G [00:09<00:09, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  39% 1.22G/3.09G [00:09<00:09, 199MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  40% 1.24G/3.09G [00:09<00:10, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  41% 1.26G/3.09G [00:09<00:10, 167MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  41% 1.28G/3.09G [00:09<00:10, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  42% 1.30G/3.09G [00:10<00:11, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  43% 1.32G/3.09G [00:10<00:26, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  43% 1.34G/3.09G [00:10<00:20, 83.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  44% 1.36G/3.09G [00:11<00:17, 100MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.bin:  45% 1.39G/3.09G [00:11<00:13, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  46% 1.42G/3.09G [00:11<00:11, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  47% 1.44G/3.09G [00:11<00:11, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  47% 1.46G/3.09G [00:11<00:11, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  48% 1.48G/3.09G [00:11<00:11, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  49% 1.50G/3.09G [00:11<00:11, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  49% 1.52G/3.09G [00:12<00:10, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  50% 1.54G/3.09G [00:12<00:09, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  51% 1.56G/3.09G [00:12<00:09, 168MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  51% 1.58G/3.09G [00:12<00:08, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  52% 1.61G/3.09G [00:12<00:08, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  53% 1.64G/3.09G [00:12<00:08, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  54% 1.66G/3.09G [00:12<00:08, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  54% 1.68G/3.09G [00:12<00:09, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  55% 1.70G/3.09G [00:13<00:08, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  56% 1.72G/3.09G [00:13<00:08, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  56% 1.74G/3.09G [00:13<00:07, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  57% 1.76G/3.09G [00:13<00:07, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  58% 1.78G/3.09G [00:13<00:06, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  58% 1.80G/3.09G [00:13<00:06, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  59% 1.82G/3.09G [00:13<00:07, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  60% 1.85G/3.09G [00:13<00:06, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  60% 1.87G/3.09G [00:13<00:06, 189MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  61% 1.89G/3.09G [00:14<00:06, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  62% 1.92G/3.09G [00:14<00:05, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  63% 1.95G/3.09G [00:14<00:05, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  64% 1.97G/3.09G [00:14<00:06, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  65% 1.99G/3.09G [00:14<00:06, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  65% 2.01G/3.09G [00:14<00:05, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  66% 2.03G/3.09G [00:14<00:05, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  67% 2.06G/3.09G [00:14<00:05, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  67% 2.08G/3.09G [00:15<00:07, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  68% 2.10G/3.09G [00:15<00:06, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  69% 2.12G/3.09G [00:15<00:06, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  69% 2.14G/3.09G [00:15<00:05, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  70% 2.16G/3.09G [00:15<00:05, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  71% 2.18G/3.09G [00:15<00:05, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  71% 2.20G/3.09G [00:15<00:05, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  72% 2.22G/3.09G [00:16<00:04, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  73% 2.24G/3.09G [00:16<00:04, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  73% 2.26G/3.09G [00:16<00:04, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  74% 2.29G/3.09G [00:16<00:04, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  75% 2.31G/3.09G [00:16<00:04, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  75% 2.33G/3.09G [00:16<00:03, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  76% 2.35G/3.09G [00:16<00:03, 189MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  77% 2.37G/3.09G [00:16<00:03, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  77% 2.39G/3.09G [00:16<00:03, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  78% 2.41G/3.09G [00:17<00:03, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  79% 2.43G/3.09G [00:17<00:03, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  79% 2.45G/3.09G [00:17<00:03, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  80% 2.47G/3.09G [00:17<00:03, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  81% 2.50G/3.09G [00:17<00:03, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  82% 2.52G/3.09G [00:17<00:03, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  83% 2.55G/3.09G [00:17<00:02, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  83% 2.57G/3.09G [00:17<00:02, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  84% 2.60G/3.09G [00:18<00:02, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  85% 2.62G/3.09G [00:18<00:02, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  86% 2.64G/3.09G [00:18<00:02, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  86% 2.66G/3.09G [00:18<00:02, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  87% 2.68G/3.09G [00:18<00:02, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  88% 2.71G/3.09G [00:18<00:01, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  88% 2.73G/3.09G [00:18<00:01, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  89% 2.75G/3.09G [00:18<00:01, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  90% 2.77G/3.09G [00:18<00:01, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  90% 2.79G/3.09G [00:19<00:01, 189MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  91% 2.82G/3.09G [00:19<00:01, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  92% 2.84G/3.09G [00:19<00:01, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  93% 2.86G/3.09G [00:19<00:01, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  93% 2.88G/3.09G [00:19<00:01, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  94% 2.90G/3.09G [00:19<00:01, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  95% 2.93G/3.09G [00:19<00:00, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  95% 2.95G/3.09G [00:19<00:00, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  96% 2.97G/3.09G [00:20<00:01, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  97% 2.99G/3.09G [00:20<00:00, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  97% 3.01G/3.09G [00:20<00:00, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  98% 3.03G/3.09G [00:20<00:00, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin:  99% 3.05G/3.09G [00:20<00:00, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.bin: 100% 3.09G/3.09G [00:20<00:00, 147MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/whisperx\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "             ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/whisperx/transcribe.py\", line 182, in cli\n",
            "    model = load_model(model_name, device=device, device_index=device_index, download_root=model_dir, compute_type=compute_type, language=args['language'], asr_options=asr_options, vad_method=vad_method, vad_options={\"chunk_size\":chunk_size, \"vad_onset\": vad_onset, \"vad_offset\": vad_offset}, task=task, local_files_only=model_cache_only, threads=faster_whisper_threads)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/whisperx/asr.py\", line 334, in load_model\n",
            "    model = model or WhisperModel(whisper_arch,\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/faster_whisper/transcribe.py\", line 634, in __init__\n",
            "    self.model = ctranslate2.models.Whisper(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "in_path = '/gdrive/MyDrive/media_proc/speedreg/in/'\n",
        "out_path = '/gdrive/MyDrive/media_proc/speedreg/out/'\n",
        "directory_path = in_path\n",
        "\n",
        "# supported extensions\n",
        "supported_extensions = ['.mp4', '.wav', '.mp3']\n",
        "\n",
        "language_param = \"\"\n",
        "if language != \"auto\":\n",
        "    language_param = f\"--language {language}\"\n",
        "\n",
        "diarize_param = \"\"\n",
        "if assign_speaker_lable:\n",
        "    diarize_param = \"--diarize --hf_token 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\"\n",
        "\n",
        "align_whisper_param = \"\"\n",
        "if align_whisper_output:\n",
        "    align_whisper_param = \"--align_model WAV2VEC2_ASR_LARGE_LV60K_960H\"\n",
        "\n",
        "prompt_param = \"\"\n",
        "if prompt != \"\":\n",
        "    prompt_param = f'--initial_prompt \"{prompt}\"'\n",
        "\n",
        "# def process_file(filename):\n",
        "#     # run = f'whisperx \"/content/APO2992689654.mp3\" --max_line_count 1 --max_line_width 100 --model medium.en --diarize --hf_token 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 --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H'\n",
        "#     run = f'whisperx \"{filename}\" --model {model_size} {language_param} --output_dir . {prompt_param} {diarize_param} {align_whisper_param}'\n",
        "#     !{run}\n",
        "\n",
        "#     print(\"Start to download subtitle files\")\n",
        "#     # start to download file\n",
        "#     base_filename = os.path.splitext(filename)[0]\n",
        "#     srt_filename = base_filename + '.srt'\n",
        "#     json_filename = base_filename + '.json'\n",
        "\n",
        "#     files.download(srt_filename)\n",
        "#     files.download(json_filename)\n",
        "\n",
        "import os, shutil\n",
        "def calculate_relative_path(directory_path, filename):\n",
        "    # 获取指定目录的绝对路径\n",
        "    abs_directory_path = os.path.abspath(directory_path)\n",
        "\n",
        "    # 获取给定文件名的绝对路径\n",
        "    abs_file_path = os.path.abspath(filename)\n",
        "\n",
        "    # 确保给定的文件名在指定目录下的子目录树中\n",
        "    if not abs_file_path.startswith(abs_directory_path):\n",
        "        raise ValueError(\"The given filename is not in the specified directory tree.\")\n",
        "\n",
        "    # 计算相对路径\n",
        "    relative_path = os.path.relpath(abs_file_path, abs_directory_path)\n",
        "    return relative_path\n",
        "\n",
        "def make_out_relative_path(out_path, filename):\n",
        "    # 计算出filename的路径在directory_path下的子目录树\n",
        "    relative_path = calculate_relative_path(in_path, filename)\n",
        "    print(relative_path)\n",
        "    existing_directory = os.path.join(out_path, relative_path)\n",
        "    if os.path.exists(existing_directory):\n",
        "        shutil.rmtree(existing_directory)\n",
        "\n",
        "    # 在另一个目录下创建子目录\n",
        "    new_directory = os.path.join(out_path, relative_path)\n",
        "    os.makedirs(new_directory, exist_ok=True)\n",
        "    return new_directory\n",
        "\n",
        "def process_file(filename):\n",
        "\n",
        "    new_directory = make_out_relative_path(out_path, filename)\n",
        "    print(new_directory)\n",
        "    # run = f'whisper_timestamped \"/content/APO2992689654.mp3\" --max_line_count 1 --max_line_width 100 --model medium.en --diarize --hf_token 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 --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H'\n",
        "    # run = f'whisper_timestamped \"{filename}\" --model {model_size} {language_param} --output_dir {new_directory} {prompt_param} {diarize_param} {align_whisper_param}'\n",
        "    # !{run}\n",
        "\n",
        "    run = f'whisperx \"{filename}\" --model {model_size} {language_param} --output_dir {new_directory} {prompt_param} {diarize_param} {align_whisper_param}'\n",
        "    !{run}\n",
        "\n",
        "    # print(\"Start to download subtitle files\")\n",
        "    # # start to download file\n",
        "    # base_filename = os.path.splitext(filename)[0]\n",
        "    # srt_filename = base_filename + '.srt'\n",
        "    # json_filename = base_filename + '.words.json'\n",
        "\n",
        "    # files.download(srt_filename)\n",
        "    # files.download(json_filename)\n",
        "\n",
        "def process():\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith(tuple(supported_extensions)):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(file_path)\n",
        "                process_file(file_path)\n",
        "\n",
        "process()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name libcudnn_ops_infer.so.8"
      ],
      "metadata": {
        "id": "o13nxfTnCcoU",
        "outputId": "a4c4e515-f44c-4189-a455-e427db359ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/68/task/68/net’: Invalid argument\n",
            "find: ‘/proc/68/net’: Invalid argument\n",
            "find: ‘/proc/2766/task/2766/net’: Invalid argument\n",
            "find: ‘/proc/2766/net’: Invalid argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -name 'libcublas.so*' -o -name 'libcudnn_ops*'"
      ],
      "metadata": {
        "id": "px23Bv42C94K"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}