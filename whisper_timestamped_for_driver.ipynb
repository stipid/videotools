{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stipid/videotools/blob/main/whisper_timestamped_for_driver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Pgww7RuFUW",
        "outputId": "909b107e-27d3-4f20-a956-57c8573f1042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 11 05:21:22 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# @title *通用参数/Required settings:**\n",
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# @markdown #### **Initial prompt**\n",
        "# @markdown Prompts can be very helpful for correcting specific words or acronyms that the model often misrecognizes in the audio.\n",
        "prompt = \"ChatGPT, LLM, OpenAI, DevDay, DALL-E.\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### **Directory Path**\n",
        "# @markdown where your audio-video files are located from Coloab\n",
        "# directory_path = \"/content\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### Model\n",
        "model_size = \"large-v2\"  # @param [\"base\", \"base.en\", \"small\", \"small.en\",\"medium\", \"medium.en\", \"large-v1\",\"large-v2\",\"large-v3\"]\n",
        "\n",
        "# @markdown #### Language\n",
        "language = \"en\" # @param [\"auto\", \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\", \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\", \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\", \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\", \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\", \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\", \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\", \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\", \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\", \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\"]\n",
        "\n",
        "# @markdown #### Filename Type\n",
        "# @markdown Use YouTube title as file name by default\n",
        "filename_type = \"title\"  # @param [\"title\", \"id\"]\n",
        "\n",
        "# @markdown #### Assign speaker labels\n",
        "# @markdown Recognize speakers\n",
        "assign_speaker_lable = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown #### Align whisper output\n",
        "align_whisper_output = False # @param {type:\"boolean\"}\n",
        "\n",
        "# supported extensions\n",
        "supported_extensions = ['.mp4', '.wav', '.mp3']\n",
        "\n",
        "in_path = '/gdrive/MyDrive/media_proc/speedreg/in/'\n",
        "\n",
        "out_path = '/gdrive/MyDrive/media_proc/speedreg/out/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80yOVjb-vAsD"
      },
      "source": [
        "# Install Whisper Timestamped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcc35ui3ux8l",
        "outputId": "ecb57e09-b85d-4f3e-fba9-fe1db323a9b5",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for whisper-timestamped (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# add 20241029 refer https://github.com/ufal/whisper_streaming/issues/129\n",
        "# add 20250302\n",
        "# ! pip install openai-whisper==20231117\n",
        "\n",
        "! pip install -q git+https://github.com/linto-ai/whisper-timestamped\n",
        "# ! pip install matplotlib\n",
        "\n",
        "# ! pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基础目录操作"
      ],
      "metadata": {
        "id": "jnsUqC2sjnDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, shutil\n",
        "def enum_files():\n",
        "  for root, dirs, files in os.walk(in_path):\n",
        "    for file in files:\n",
        "      if file.endswith(tuple(supported_extensions)):\n",
        "        file_path = os.path.join(root, file)\n",
        "        print(file_path)\n",
        "\n",
        "def calculate_relative_path(directory_path, filename):\n",
        "  # 获取指定目录的绝对路径\n",
        "  abs_directory_path = os.path.abspath(directory_path)\n",
        "\n",
        "  # 获取给定文件名的绝对路径,包括文件名本身\n",
        "  abs_file_path = os.path.abspath(filename)\n",
        "\n",
        "  #去除abs_file_path文件名中的扩展名\n",
        "  abs_file_path = os.path.splitext(abs_file_path)[0]\n",
        "\n",
        "  # 确保给定的文件名在指定目录下的子目录树中\n",
        "  if not abs_file_path.startswith(abs_directory_path):\n",
        "    raise ValueError(\"The given filename is not in the specified directory tree.\")\n",
        "\n",
        "  # print(\"abs_file_path:\" + abs_file_path)\n",
        "  # print(\"abs_directory_path:\" + abs_directory_path)\n",
        "  # 计算相对路径\n",
        "  relative_path = os.path.relpath(abs_file_path, abs_directory_path)\n",
        "  return relative_path\n",
        "\n",
        "def make_out_relative_path(out_path, filename, annots=[]):\n",
        "  # 计算出filename的路径在directory_path下的子目录树\n",
        "  relative_path = calculate_relative_path(in_path, filename)\n",
        "  # print(relative_path)\n",
        "  if len(annots) > 0:\n",
        "    for annot in annots:\n",
        "      relative_path += \"_\" + annot\n",
        "\n",
        "  #替换relative_path中' ' '-' '.'等为'_'\n",
        "  relative_path = relative_path.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
        "\n",
        "  new_directory = os.path.join(out_path, relative_path)\n",
        "  while os.path.exists(new_directory):\n",
        "    new_directory += \"_1\"\n",
        "  # print(new_directory)\n",
        "  os.makedirs(new_directory, exist_ok=True)\n",
        "  return new_directory\n",
        "\n",
        "def enum_files_ex():\n",
        "  for root, dirs, files in os.walk(in_path):\n",
        "    for file in files:\n",
        "      if file.endswith(tuple(supported_extensions)):\n",
        "        file_path = os.path.join(root, file)\n",
        "        new_directory = make_out_relative_path(out_path, file_path, ['ts', model_size])\n",
        "        print(file_path)\n",
        "        print(new_directory)"
      ],
      "metadata": {
        "id": "BhdNlqk1cTHl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enum_files_ex()"
      ],
      "metadata": {
        "id": "1rBjdG8IintE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gdriver连接"
      ],
      "metadata": {
        "id": "eIrO6ciXmP56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJXxWPzU7c6",
        "outputId": "600d2f77-587c-4145-e388-351453f27146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/media_proc/speedreg/in/Diary12.mp3\n",
            "/gdrive/MyDrive/media_proc/speedreg/in/Diary11.mp3\n"
          ]
        }
      ],
      "source": [
        "# Please BE VERY CAREFUL, this will link your entire drive.\n",
        "# So don't edit code, except the one that says 'Customize the following options',\n",
        "# or you might mess up your files.\n",
        "# IF YOU DO NO WANT TO LINK DRIVE, please see below for an alternative!\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "enum_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEqkpyuQL5_"
      },
      "source": [
        "# Get Subtitle Files using WhisperX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qWk9Y3Uxv9qu"
      },
      "outputs": [],
      "source": [
        "directory_path = in_path\n",
        "\n",
        "language_param = \"\"\n",
        "if language != \"auto\":\n",
        "    language_param = f\"--language {language}\"\n",
        "\n",
        "diarize_param = \"\"\n",
        "if assign_speaker_lable:\n",
        "    diarize_param = \"--diarize --hf_token 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\"\n",
        "\n",
        "align_whisper_param = \"\"\n",
        "# if align_whisper_output:\n",
        "#     align_whisper_param = \"--align_model WAV2VEC2_ASR_LARGE_LV60K_960H\"\n",
        "\n",
        "prompt_param = \"\"\n",
        "# if prompt != \"\":\n",
        "#     prompt_param = f'--initial_prompt \"{prompt}\"'\n",
        "\n",
        "# output_format = '--output_format \"srt,json,vtt\"'\n",
        "output_format = '--output_format \"srt,json\"'\n",
        "\n",
        "def process_file(filename):\n",
        "\n",
        "    new_directory = make_out_relative_path(out_path, filename, ['ts', model_size])\n",
        "    # run = f'whisper_timestamped \"/content/APO2992689654.mp3\" --max_line_count 1 --max_line_width 100 --model medium.en --diarize --hf_token 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 --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H'\n",
        "    run = f'whisper_timestamped \"{filename}\" --model {model_size} {language_param} --output_dir {new_directory} {prompt_param} {diarize_param} {align_whisper_param} {output_format}'\n",
        "    print(run)\n",
        "    !{run}\n",
        "\n",
        "    # print(\"Start to download subtitle files\")\n",
        "    # # start to download file\n",
        "    # base_filename = os.path.splitext(filename)[0]\n",
        "    # srt_filename = base_filename + '.srt'\n",
        "    # json_filename = base_filename + '.words.json'\n",
        "\n",
        "    # files.download(srt_filename)\n",
        "    # files.download(json_filename)\n",
        "\n",
        "def process():\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith(tuple(supported_extensions)):\n",
        "                file_path = os.path.join(root, file)\n",
        "                process_file(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 开始执行"
      ],
      "metadata": {
        "id": "ZTX4ovjLkQP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ATNfXNzkVky",
        "outputId": "856bfb2b-950c-48da-edaf-05c634a83ccc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper_timestamped \"/gdrive/MyDrive/media_proc/speedreg/in/Diary12.mp3\" --model large-v2 --language en --output_dir /gdrive/MyDrive/media_proc/speedreg/out/Diary12_ts_large_v2    --output_format \"srt,json\"\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:69: UserWarning: /root/.cache/whisper/large-v2.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
            "  warnings.warn(\n",
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:50<00:00, 61.4MiB/s]\n",
            "100% 12303/12303 [00:33<00:00, 364.87frames/s]\n",
            "whisper_timestamped \"/gdrive/MyDrive/media_proc/speedreg/in/Diary11.mp3\" --model large-v2 --language en --output_dir /gdrive/MyDrive/media_proc/speedreg/out/Diary11_ts_large_v2    --output_format \"srt,json\"\n",
            "100% 13677/13677 [00:35<00:00, 382.57frames/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}