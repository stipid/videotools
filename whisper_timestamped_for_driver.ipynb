{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stipid/videotools/blob/main/whisper_timestamped_for_driver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Pgww7RuFUW",
        "outputId": "857082c2-49cd-40ca-f8fd-d3e54b85075f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# @title *通用参数/Required settings:**\n",
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# @markdown #### **Initial prompt**\n",
        "# @markdown Prompts can be very helpful for correcting specific words or acronyms that the model often misrecognizes in the audio.\n",
        "prompt = \"ChatGPT, LLM, OpenAI, DevDay, DALL-E.\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### **Directory Path**\n",
        "# @markdown where your audio-video files are located from Coloab\n",
        "# directory_path = \"/content\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### Model\n",
        "model_size = \"large-v2\"  # @param [\"base\", \"base.en\", \"small\", \"small.en\",\"medium\", \"medium.en\", \"large-v1\",\"large-v2\",\"large-v3\"]\n",
        "\n",
        "# @markdown #### Language\n",
        "language = \"en\" # @param [\"auto\", \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\", \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\", \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\", \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\", \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\", \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\", \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\", \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\", \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\", \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\"]\n",
        "\n",
        "# @markdown #### Filename Type\n",
        "# @markdown Use YouTube title as file name by default\n",
        "filename_type = \"title\"  # @param [\"title\", \"id\"]\n",
        "\n",
        "# @markdown #### Assign speaker labels\n",
        "# @markdown Recognize speakers\n",
        "assign_speaker_lable = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown #### Align whisper output\n",
        "align_whisper_output = False # @param {type:\"boolean\"}\n",
        "\n",
        "# supported extensions\n",
        "supported_extensions = ['.mp4', '.wav', '.mp3']\n",
        "\n",
        "in_path = '/gdrive/MyDrive/media_proc/speedreg/in/'\n",
        "\n",
        "out_path = '/gdrive/MyDrive/media_proc/speedreg/out/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80yOVjb-vAsD"
      },
      "source": [
        "# Install Whisper Timestamped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcc35ui3ux8l",
        "outputId": "7ff3afba-9967-4bd8-bab6-00b30b76ed51",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/linto-ai/whisper-timestamped\n",
            "  Cloning https://github.com/linto-ai/whisper-timestamped to /tmp/pip-req-build-5vzoqpf1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/linto-ai/whisper-timestamped /tmp/pip-req-build-5vzoqpf1\n",
            "  Resolved https://github.com/linto-ai/whisper-timestamped to commit d953bc3fa20a8a27c8d33218084aac5e3f7b7636\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from whisper-timestamped==1.15.8) (3.0.12)\n",
            "Collecting dtw-python (from whisper-timestamped==1.15.8)\n",
            "  Downloading dtw_python-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai-whisper (from whisper-timestamped==1.15.8)\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from dtw-python->whisper-timestamped==1.15.8) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from dtw-python->whisper-timestamped==1.15.8) (1.26.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper->whisper-timestamped==1.15.8) (0.61.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper->whisper-timestamped==1.15.8) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper->whisper-timestamped==1.15.8) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper->whisper-timestamped==1.15.8) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper->whisper-timestamped==1.15.8) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper->whisper-timestamped==1.15.8) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper->whisper-timestamped==1.15.8) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper->whisper-timestamped==1.15.8) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper->whisper-timestamped==1.15.8) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper->whisper-timestamped==1.15.8)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper->whisper-timestamped==1.15.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper->whisper-timestamped==1.15.8) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped==1.15.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped==1.15.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped==1.15.8) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped==1.15.8) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper->whisper-timestamped==1.15.8) (3.0.2)\n",
            "Downloading dtw_python-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (801 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.7/801.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: whisper-timestamped, openai-whisper\n",
            "  Building wheel for whisper-timestamped (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper-timestamped: filename=whisper_timestamped-1.15.8-py3-none-any.whl size=53759 sha256=8eb57bfbaa0c71f1c1c17a347ba06bbe20f6d4755abfaab52858725ead03aa79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f3s5_s4x/wheels/7b/3d/fa/7ac1d19f7cf2d9921822e0d06c92eab35b31ab252039a981e3\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=fecdb23d644b95dc580c79f20d2f3fc910f03be363eeb092bf602c65d0d565fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built whisper-timestamped openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dtw-python, nvidia-cusolver-cu12, openai-whisper, whisper-timestamped\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dtw-python-1.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0 whisper-timestamped-1.15.8\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# add 20241029 refer https://github.com/ufal/whisper_streaming/issues/129\n",
        "# add 20250302\n",
        "# ! pip install openai-whisper==20231117\n",
        "\n",
        "! pip install git+https://github.com/linto-ai/whisper-timestamped\n",
        "# ! pip install matplotlib\n",
        "\n",
        "# ! pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJXxWPzU7c6",
        "outputId": "c71a2078-c679-4c04-af84-fb127bb91d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/media_proc/speedreg/in/Diary12.mp3\n",
            "/gdrive/MyDrive/media_proc/speedreg/in/Diary11.mp3\n"
          ]
        }
      ],
      "source": [
        "# Please BE VERY CAREFUL, this will link your entire drive.\n",
        "# So don't edit code, except the one that says 'Customize the following options',\n",
        "# or you might mess up your files.\n",
        "# IF YOU DO NO WANT TO LINK DRIVE, please see below for an alternative!\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "enum_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基础目录操作"
      ],
      "metadata": {
        "id": "jnsUqC2sjnDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, shutil\n",
        "def enum_files():\n",
        "  for root, dirs, files in os.walk(in_path):\n",
        "    for file in files:\n",
        "      if file.endswith(tuple(supported_extensions)):\n",
        "        file_path = os.path.join(root, file)\n",
        "        print(file_path)\n",
        "\n",
        "def calculate_relative_path(directory_path, filename):\n",
        "  # 获取指定目录的绝对路径\n",
        "  abs_directory_path = os.path.abspath(directory_path)\n",
        "\n",
        "  # 获取给定文件名的绝对路径,包括文件名本身\n",
        "  abs_file_path = os.path.abspath(filename)\n",
        "\n",
        "  #去除abs_file_path文件名中的扩展名\n",
        "  abs_file_path = os.path.splitext(abs_file_path)[0]\n",
        "\n",
        "  # 确保给定的文件名在指定目录下的子目录树中\n",
        "  if not abs_file_path.startswith(abs_directory_path):\n",
        "    raise ValueError(\"The given filename is not in the specified directory tree.\")\n",
        "\n",
        "  # print(\"abs_file_path:\" + abs_file_path)\n",
        "  # print(\"abs_directory_path:\" + abs_directory_path)\n",
        "  # 计算相对路径\n",
        "  relative_path = os.path.relpath(abs_file_path, abs_directory_path)\n",
        "  return relative_path\n",
        "\n",
        "def make_out_relative_path(out_path, filename, annots=[]):\n",
        "  # 计算出filename的路径在directory_path下的子目录树\n",
        "  relative_path = calculate_relative_path(in_path, filename)\n",
        "  # print(relative_path)\n",
        "  if len(annots) > 0:\n",
        "    for annot in annots:\n",
        "      relative_path += \"_\" + annot\n",
        "\n",
        "  #替换relative_path中' ' '-' '.'等为'_'\n",
        "  relative_path = relative_path.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
        "\n",
        "  new_directory = os.path.join(out_path, relative_path)\n",
        "  while os.path.exists(new_directory):\n",
        "    new_directory += \"_1\"\n",
        "  # print(new_directory)\n",
        "  os.makedirs(new_directory, exist_ok=True)\n",
        "  return new_directory\n",
        "\n",
        "def enum_files_ex():\n",
        "  for root, dirs, files in os.walk(in_path):\n",
        "    for file in files:\n",
        "      if file.endswith(tuple(supported_extensions)):\n",
        "        file_path = os.path.join(root, file)\n",
        "        new_directory = make_out_relative_path(out_path, file_path, ['ts', model_size])\n",
        "        print(file_path)\n",
        "        print(new_directory)"
      ],
      "metadata": {
        "id": "BhdNlqk1cTHl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enum_files_ex()"
      ],
      "metadata": {
        "id": "1rBjdG8IintE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEqkpyuQL5_"
      },
      "source": [
        "# Get Subtitle Files using WhisperX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qWk9Y3Uxv9qu"
      },
      "outputs": [],
      "source": [
        "directory_path = in_path\n",
        "\n",
        "language_param = \"\"\n",
        "if language != \"auto\":\n",
        "    language_param = f\"--language {language}\"\n",
        "\n",
        "diarize_param = \"\"\n",
        "if assign_speaker_lable:\n",
        "    diarize_param = \"--diarize --hf_token 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\"\n",
        "\n",
        "align_whisper_param = \"\"\n",
        "# if align_whisper_output:\n",
        "#     align_whisper_param = \"--align_model WAV2VEC2_ASR_LARGE_LV60K_960H\"\n",
        "\n",
        "prompt_param = \"\"\n",
        "# if prompt != \"\":\n",
        "#     prompt_param = f'--initial_prompt \"{prompt}\"'\n",
        "\n",
        "# output_format = '--output_format \"srt,json,vtt\"\n",
        "output_format = '--output_format \"srt,json\"'\n",
        "\n",
        "def process_file(filename):\n",
        "\n",
        "    new_directory = make_out_relative_path(out_path, filename)\n",
        "    # run = f'whisper_timestamped \"/content/APO2992689654.mp3\" --max_line_count 1 --max_line_width 100 --model medium.en --diarize --hf_token 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 --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H'\n",
        "    run = f'whisper_timestamped \"{filename}\" --model {model_size} {language_param} --output_dir {new_directory} {prompt_param} {diarize_param} {align_whisper_param} {output_format}'\n",
        "    print(run)\n",
        "    # !{run}\n",
        "\n",
        "    # print(\"Start to download subtitle files\")\n",
        "    # # start to download file\n",
        "    # base_filename = os.path.splitext(filename)[0]\n",
        "    # srt_filename = base_filename + '.srt'\n",
        "    # json_filename = base_filename + '.words.json'\n",
        "\n",
        "    # files.download(srt_filename)\n",
        "    # files.download(json_filename)\n",
        "\n",
        "def process():\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith(tuple(supported_extensions)):\n",
        "                file_path = os.path.join(root, file)\n",
        "                process_file(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 开始执行"
      ],
      "metadata": {
        "id": "ZTX4ovjLkQP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process()"
      ],
      "metadata": {
        "id": "0ATNfXNzkVky",
        "outputId": "b5ecdce7-d66a-4ec5-fa64-05c04b5fbd5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper_timestamped \"/gdrive/MyDrive/media_proc/speedreg/in/Diary12.mp3\" --model large-v2 --language en --output_dir /gdrive/MyDrive/media_proc/speedreg/out/Diary12_1_1_1_1    --output_format \"srt,json\"\n",
            "whisper_timestamped \"/gdrive/MyDrive/media_proc/speedreg/in/Diary11.mp3\" --model large-v2 --language en --output_dir /gdrive/MyDrive/media_proc/speedreg/out/Diary11_1_1_1_1    --output_format \"srt,json\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}